{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing block\n",
    "from pa2 import Dictionary\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_training_df(url):\n",
    "    r = requests.get(url)\n",
    "    temptext = r.text\n",
    "    with open(\"temp.txt\", \"w\") as text_file:\n",
    "        text_file.write(str(temptext))\n",
    "    text_file.close()\n",
    "\n",
    "    templist = temptext.split(\"\\n\")\n",
    "    for i in range(len(templist)):\n",
    "        templist[i] = templist[i].split()\n",
    "        if \"\\r\" in templist[i]:\n",
    "            templist[i].pop[-1]\n",
    "\n",
    "    training_dict = {}\n",
    "    for item in templist:\n",
    "        training_dict[item[0]] = item[1:]\n",
    "\n",
    "    training_df = pd.DataFrame(training_dict)\n",
    "    for cat in range(training_df.shape[1]):\n",
    "        for item in range(training_df.shape[0]):\n",
    "            training_df.iloc[item, cat] = int(training_df.iloc[item, cat]) -1\n",
    "    print(\"training_df created\")\n",
    "    return training_df\n",
    "\n",
    "def train_term_extract(all_doc, training_df):\n",
    "    list_list_preprocess = [] ## index 0 means cat1\n",
    "    for cat in range(training_df.shape[1]):\n",
    "        list_list_preprocess.append([])\n",
    "        for index in training_df[str(cat +1)]:\n",
    "            list_list_preprocess[cat].append(deepcopy(all_doc.preprocess_list[index].word_dic))\n",
    "            # use .word_dic to get each word\n",
    "    print(\"train_term created\")\n",
    "    return list_list_preprocess\n",
    "\n",
    "\n",
    "def term_cat_making(list_list_dict, cat):\n",
    "    dict_matrix = {} # key: each term, value: matrix for present or not in each category\n",
    "    for c in range(cat):\n",
    "        per_cat_sum = len(list_list_dict[c])\n",
    "        for doc in range(per_cat_sum):\n",
    "            for term in list_list_dict[c][doc].keys():\n",
    "                if term not in dict_matrix:\n",
    "                    n11 = n10 = n01 = n00 = likelihood_ratio = chi_sqr = np.nan\n",
    "                    dict_matrix[term] = pd.DataFrame(np.array([[0, per_cat_sum, n11, n10, n01, n00, likelihood_ratio, chi_sqr]] * cat), columns=[\"present\", \"absent\", \"n11\", \"n10\", \"n01\", \"n00\", \"likelihood_ratio\", \"chi_sqr\"])\n",
    "                    index_name = {}\n",
    "                    for i in range(cat):\n",
    "                        index_name[i] = \"cat_\" + str(i)\n",
    "                    dict_matrix[term] = dict_matrix[term].rename(index=index_name)\n",
    "                    # print(dict_matrix[term])\n",
    "\n",
    "                dict_matrix[term][\"present\"][c] += 1  # df +1\n",
    "                dict_matrix[term][\"absent\"][c] -= 1\n",
    "    print(\"term_cat_matrix created\")\n",
    "    return dict_matrix\n",
    "\n",
    "def fill_nx(matrix, cat):\n",
    "    # get matrix for each term\n",
    "    # return modified matrix\n",
    "    for c in range(cat):\n",
    "        matrix[\"n11\"][c] = matrix[\"present\"][c]\n",
    "        matrix[\"n10\"][c] = matrix[\"absent\"][c]\n",
    "        matrix[\"n01\"][c] = matrix[\"present\"].sum() - matrix[\"n11\"][c]\n",
    "        matrix[\"n00\"][c] = matrix[\"absent\"].sum() - matrix[\"n10\"][c]\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cal_ratio(matrix, cat):\n",
    "    # get matrix for each term\n",
    "    # return likelihood ratio of term in all cat\n",
    "    if matrix[\"n00\"].sum() == 0:\n",
    "        matrix = fill_nx(matrix, cat)\n",
    "\n",
    "    for cat in range(matrix.shape[0]):\n",
    "        n11 = matrix[\"n11\"][cat]\n",
    "        n10 = matrix[\"n10\"][cat]\n",
    "        n01 = matrix[\"n01\"][cat]\n",
    "        n00 = matrix[\"n00\"][cat]\n",
    "        N = n11 + n10 + n01 + n00\n",
    "\n",
    "        ## likelihood ratio\n",
    "        pt = (n11 + n01) / N\n",
    "        p1 = n11 / (n11 + n10)\n",
    "        p2 = n01 / (n01 + n00)\n",
    "\n",
    "        likelihood = -2 * np.log10((((pt ** n11) * (1 - pt) ** n10) * ((pt ** n01) * (1 - pt) ** n00)) /\n",
    "                              (((p1**n11) * (1 - p1)**n10) * ((p2**n01) * (1 - p2)**n00)))\n",
    "        matrix[\"likelihood_ratio\"][cat] = likelihood\n",
    "\n",
    "        ## chi square\n",
    "        e11 = (n11 + n01) * (n11 + n10) / N\n",
    "        e10 = (n11 + n10) * (n00 + n10) / N\n",
    "        e01 = (n11 + n01) * (n01 + n00) / N\n",
    "        e00 = (n00 + n01) * (n00 + n10) / N\n",
    "\n",
    "        chi_square = (n11 - e11)**2 / e11 + (n10 - e10)**2 / e11 + (n01 - e01)**2 / e11 + (n00 - e00)**2 / e11\n",
    "        matrix[\"chi_sqr\"][cat] = chi_square\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_term_extract(all_doc, training_df):\n",
    "    temp = []\n",
    "    for index, row in training_df.iterrows():\n",
    "        temp.append(row.to_list())\n",
    "    train_ids = []\n",
    "    for row in temp:\n",
    "        for item in row:\n",
    "            train_ids.append(item)\n",
    "\n",
    "    dict_dict = {} ## key:doc_id(in real), values:preprocess_list\n",
    "    for index in range(len(all_doc.preprocess_list)):\n",
    "        if index in train_ids:\n",
    "            continue\n",
    "        dict_dict[index +1] = all_doc.preprocess_list[index].word_dic\n",
    "        # use .word_dic to get each word\n",
    "    return dict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_selection(dict_df, method=\"sum_likelihood\"):\n",
    "    store_score = {}\n",
    "    feature_list = []\n",
    "    feature_upper = 500\n",
    "\n",
    "    if method == \"sum_likelihood\":\n",
    "        ## top 500 from sum of the likelihood ratio\n",
    "        for term in dict_df.keys():\n",
    "            store_score[term] = dict_df[term][\"likelihood_ratio\"].sum()\n",
    "        feature_list = sorted(store_score.items(), key=lambda item: item[1], reverse=True)\n",
    "        for rank in range(feature_upper):\n",
    "            feature_list.append(feature_list[rank][0])\n",
    "\n",
    "    if method == \"max_likelihood\":\n",
    "        ## top 500 from the likelihood ratio\n",
    "        for term in dict_df.keys():\n",
    "            store_score[term] = dict_df[term][\"likelihood_ratio\"].max()\n",
    "        feature_list = sorted(store_score.items(), key=lambda item: item[1], reverse=True)\n",
    "        for rank in range(feature_upper):\n",
    "            feature_list.append(feature_list[rank][0])\n",
    "\n",
    "    if method == \"max_chi\":\n",
    "        ## top 500 from the chi_sqr ratio\n",
    "        for term in dict_df.keys():\n",
    "            store_score[term] = dict_df[term][\"chi_sqr\"].max()\n",
    "        feature_list = sorted(store_score.items(), key=lambda item: item[1], reverse=True)\n",
    "        for rank in range(feature_upper):\n",
    "            feature_list.append(feature_list[rank][0])\n",
    "\n",
    "    if method == \"hy_max\":\n",
    "        ## top 500 from the hybrid ratio\n",
    "        store_score_like = {}\n",
    "        store_score_chi = {}\n",
    "        for term in dict_df.keys():\n",
    "            store_score_like[term] = dict_df[term][\"likelihood_ratio\"].max()\n",
    "            store_score_chi[term] = dict_df[term][\"chi_sqr\"].max()\n",
    "        rank_like = sorted(store_score_like.items(), key=lambda item: item[1], reverse=True)\n",
    "        rank_chi = sorted(store_score_chi.items(), key=lambda item: item[1], reverse=True)\n",
    "        buffer = set()\n",
    "        def hybrid_rank(check, rank_list, term):\n",
    "            if term in check:\n",
    "                check.discard(term)\n",
    "                rank_list.append(term)\n",
    "            else:\n",
    "                check.add(term)\n",
    "\n",
    "        for i in range(len(rank_chi)):\n",
    "            hybrid_rank(buffer, feature_list, rank_chi[i][0])\n",
    "            hybrid_rank(buffer, feature_list, rank_like[i][0])\n",
    "            if len(feature_list) == feature_upper:\n",
    "                break\n",
    "\n",
    "    print(\"feature_selection with %s completed\" %method)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cal_condprob(cat, list_list_preprocess, list_term):\n",
    "    tf_dict_list = {}\n",
    "    dict_list = {}\n",
    "    for term in list_term:\n",
    "        tf_dict_list[term] = [0] * cat\n",
    "        dict_list[term] = [0] * cat\n",
    "    for c in range(cat):\n",
    "        for doc in list_list_preprocess[c]:\n",
    "            for term in doc.keys():\n",
    "                if term in list_term:\n",
    "                    tf = len(doc[term])\n",
    "                    tf_dict_list[term][c] += tf\n",
    "        for term in list_term:\n",
    "            dict_list[term][c] = (int(tf_dict_list[term][c]) + 1) / (sum(tf_dict_list[term][0: -1]) + len(list_term))\n",
    "    print(\"cal_condprob completed\")\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_multi_NB(cat, features, condprob, test_doc):\n",
    "    extracted = []\n",
    "    score = [0] * cat\n",
    "    for term in test_doc:\n",
    "        if term in features:\n",
    "            extracted.append(term)\n",
    "    for c in range(cat):\n",
    "        for term in extracted:\n",
    "            score[c] += math.log10(condprob[term][c])\n",
    "    predict = 0\n",
    "    for c in range(cat):\n",
    "        if score[c] >= score[predict]:\n",
    "            predict = c\n",
    "    return predict+1 ## right class for the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_df created\n",
      "train_term created\n",
      "term_cat_matrix created\n",
      "cal_likelihood completed\n",
      "feature_selection with max_chi completed\n",
      "cal_condprob completed\n",
      "prediction made\n",
      "result_05_max_chi.csv file saved\n"
     ]
    }
   ],
   "source": [
    "# Press the green button in the gutter to run the script.\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    url = \"https://ceiba.ntu.edu.tw/course/88ca22/content/training.txt\"\n",
    "    training_df = get_training_df(url)\n",
    "\n",
    "    all_doc = Dictionary()\n",
    "    all_doc.preprocess_all_file(\"D:\\Desktop\\IR\\PA2\\IRTM\")\n",
    "\n",
    "    train_term = train_term_extract(all_doc, training_df) ## type: list(cat) of list(docs) of dict(word_dic)\n",
    "    cat = len(train_term)\n",
    "    term_cat_matrix = term_cat_making(train_term, cat)  ## type: dict, make a matrix for each term\n",
    "\n",
    "\n",
    "    for term in term_cat_matrix.keys():\n",
    "        ## traverse all terms to calculate likelihood\n",
    "        term_cat_matrix[term] = cal_ratio(term_cat_matrix[term], cat)\n",
    "    print(\"cal_likelihood completed\")\n",
    "\n",
    "    ## feature selection\n",
    "    features = feature_selection(term_cat_matrix, method=\"max_chi\") ## type: list\n",
    "    \n",
    "    prior = 1/13\n",
    "    ## prior of each category is identical, so we skip prior\n",
    "\n",
    "    condprob = cal_condprob(cat, train_term, features) ## type: dict(term) of list(probability for each cat)\n",
    "\n",
    "    #################################\n",
    "    ########### TEST PART ###########\n",
    "    #################################\n",
    "    test_term = test_term_extract(all_doc, training_df) ## tpye: dict, key: real doc name/ id, value: word_dict\n",
    "\n",
    "    #################################\n",
    "    ######## MAKE PREDICTION ########\n",
    "    #################################\n",
    "    \n",
    "    predicts = []\n",
    "    id = []\n",
    "    for key in test_term.keys():\n",
    "        id.append(key)\n",
    "        predicts.append(apply_multi_NB(cat, features, condprob, test_term[key].keys()))\n",
    "    result = pd.DataFrame()\n",
    "    result[\"Id\"] = id\n",
    "    result[\"Value\"] = predicts\n",
    "    print(\"prediction made\")\n",
    "\n",
    "    file_name = \"result_05_max_chi.csv\"\n",
    "    result.to_csv(file_name, index=False)\n",
    "    print(file_name, \"file saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 用字典把每個訓練用的 term 存你來，並用表的方式計算 likelihood ratio, chi_square"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "term_cat_matrix[\"navi\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term_cat_matrix[\"navi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>present</th>\n",
       "      <th>absent</th>\n",
       "      <th>n11</th>\n",
       "      <th>n10</th>\n",
       "      <th>n01</th>\n",
       "      <th>n00</th>\n",
       "      <th>likelihood_ratio</th>\n",
       "      <th>chi_sqr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat_0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4.575504</td>\n",
       "      <td>46.678063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.203189</td>\n",
       "      <td>1.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.767034</td>\n",
       "      <td>16.455840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_8</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>16.750614</td>\n",
       "      <td>189.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>2.027056</td>\n",
       "      <td>8.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        present  absent   n11   n10   n01    n00  likelihood_ratio     chi_sqr\n",
       "cat_0       7.0     8.0   7.0   8.0  20.0  160.0          4.575504   46.678063\n",
       "cat_1       0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692\n",
       "cat_2       0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692\n",
       "cat_3       3.0    12.0   3.0  12.0  24.0  156.0          0.203189    1.641026\n",
       "cat_4       0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692\n",
       "cat_5       0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692\n",
       "cat_6       0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692\n",
       "cat_7       5.0    10.0   5.0  10.0  22.0  158.0          1.767034   16.455840\n",
       "cat_8      12.0     3.0  12.0   3.0  15.0  165.0         16.750614  189.641026\n",
       "cat_9       0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692\n",
       "cat_10      0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692\n",
       "cat_11      0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692\n",
       "cat_12      0.0    15.0   0.0  15.0  27.0  153.0          2.027056    8.307692"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_cat_matrix[\"navi\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}